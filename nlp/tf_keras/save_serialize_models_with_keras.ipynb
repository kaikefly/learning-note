{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: Saving Sequential models or Functional models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3_layer_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "digits (InputLayer)          [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name='digits')\n",
    "x = layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
    "x = layers.Dense(64, activation='relu', name='dense_2')(x)\n",
    "outputs = layers.Dense(10, name='predictions')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='3_layer_mlp')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.3158\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer=keras.optimizers.RMSprop())\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=1)\n",
    "\n",
    "# Reset metrics before saving so that loaded model has same state,\n",
    "# since metric states are not preserved by Model.save_weights\n",
    "model.reset_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions for future checks\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Whole-model saving**\n",
    "\n",
    "可以使用 Functional API 将模型保存成单独的文件，之后可以从该文件重建模型，而不需要创建模型的代码。文件包括：\n",
    "* 模型结构\n",
    "* 模型权重（训练过程中学习得到）\n",
    "* 训练配置（compile 中的内容）\n",
    "* 优化器和其状态（可以重新训练）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('path_to_my_model.h5')\n",
    "\n",
    "# # Recreate the exact same model purely from the file\n",
    "new_model = keras.models.load_model('path_to_my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is preserved as well:\n",
    "# you can resume training where you left off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export to SavedModel**\n",
    "\n",
    "也可以将整个模型导出为 Tensorflow SavedModel 格式，SavedModel 是 Tensorflow serving 支持的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kazh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: path_to_saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Export the model to a SavedModel\n",
    "model.save('path_to_saved_model', save_format='tf')\n",
    "\n",
    "# Recreate the exact same model\n",
    "new_model = keras.models.load_model('path_to_saved_model')\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**只保存结构**\n",
    "\n",
    "有时候，只想保存模型的结构，不想保存模型权重或优化器，这时候可以使用使用 get_config() 来获取模型的 \"config\"。config 是 Python dict，可以重建模型--重新初始化，没有之前训练学到的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '3_layer_mlp',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 784),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'name': 'digits'},\n",
       "   'name': 'digits',\n",
       "   'inbound_nodes': []},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 64,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'name': 'dense_1',\n",
       "   'inbound_nodes': [[['digits', 0, 0, {}]]]},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 64,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'name': 'dense_2',\n",
       "   'inbound_nodes': [[['dense_1', 0, 0, {}]]]},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'predictions',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 10,\n",
       "    'activation': 'linear',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'name': 'predictions',\n",
       "   'inbound_nodes': [[['dense_2', 0, 0, {}]]]}],\n",
       " 'input_layers': [['digits', 0, 0]],\n",
       " 'output_layers': [['predictions', 0, 0]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = model.get_config()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinitialized_model = keras.Model.from_config(config)\n",
    "\n",
    "# Note that the model state is not preserved! We only saved the architecture.\n",
    "new_predictions = reinitialized_model.predict(x_test)\n",
    "assert abs(np.sum(predictions - new_predictions)) > 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以使用 to_json() from_json()，这种方法将模型保存成 json 串的形式。适合于将模型结构保存到文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"class_name\": \"Model\", \"config\": {\"name\": \"3_layer_mlp\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 784], \"dtype\": \"float32\", \"sparse\": false, \"name\": \"digits\"}, \"name\": \"digits\", \"inbound_nodes\": []}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"name\": \"dense_1\", \"inbound_nodes\": [[[\"digits\", 0, 0, {}]]]}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"name\": \"dense_2\", \"inbound_nodes\": [[[\"dense_1\", 0, 0, {}]]]}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"predictions\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"name\": \"predictions\", \"inbound_nodes\": [[[\"dense_2\", 0, 0, {}]]]}], \"input_layers\": [[\"digits\", 0, 0]], \"output_layers\": [[\"predictions\", 0, 0]]}, \"keras_version\": \"2.2.4-tf\", \"backend\": \"tensorflow\"}\n"
     ]
    }
   ],
   "source": [
    "json_config = model.to_json()\n",
    "print(json_config)\n",
    "reinitialized_model = keras.models.model_from_json(json_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**只保存权重**\n",
    "\n",
    "如果只想保存权重，不保存模型结构，可以使用 get_weights() 和 set_weights()："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()  # Retrieves the state of the model\n",
    "model.set_weights(weights)  # Sets the state of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以结合使用 get_config()/from_config() 和 get_weights()/set_weights() 来重建模型。但是，不同于 model.save()，这种方法不包括训练配置和优化器，如果要接着训练必须先调用 compile()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = model.get_config()\n",
    "weights = model.get_weights()\n",
    "\n",
    "new_model = keras.Model.from_config(config)\n",
    "new_model.set_weights(weights)\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_weights() 和 set_weights() 同样有保存成文件的版本：save_weights(fpath) 和 load_weights(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save JSON config to disk\n",
    "json_config = model.to_json()\n",
    "with open('model_config.json', 'w') as json_file:\n",
    "    json_file.write(json_config)\n",
    "# Save weights to disk\n",
    "model.save_weights('path_to_my_weights.h5')\n",
    "\n",
    "# Reload the model from the 2 files we saved\n",
    "with open('model_config.json') as json_file:\n",
    "    json_config = json_file.read()\n",
    "new_model = keras.models.model_from_json(json_config)\n",
    "new_model.load_weights('path_to_my_weights.h5')\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer was not preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "记住，最简单，也是推荐的方式还是使用 save():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('path_to_my_model.h5')\n",
    "del model\n",
    "model = keras.models.load_model('path_to_my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用 Tensorflow checkpoints 只保存权重**\n",
    "\n",
    "save_weights 可以保存成 HDF5 格式，也可以保存成 tf checkpoint 格式，取决于文件的后缀，如果后缀为 \".h5\" 或 \".keras\"，保存成 HDF5 格式，否则为 Checkpoint，也可以通过 save_format 参数指定格式，参数值为 \"tf\" 或 \"h5\"。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('path_to_my_tf_checkpoint')  # 等价于下面\n",
    "model.save_weights('path_to_my_tf_checkpoint', save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2: Saving and Loading of Subclassed Models**\n",
    "\n",
    "Sequential 模型和 Functional 模型是 datastructures that represent a DAG of layers，所以它们可以安全地序列化和反序列化。A subclassed 模型不同之处是它不同 datastructure，只是一段代码。模型的结构在 call 方法中定义，这意味着模型结构不能被安全序列化。导入模型时，必须访问创建模型的代码。\n",
    "\n",
    "下面的 subclassed 模型，结构和上面的一致："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerMLP(keras.Model):\n",
    "    def __init__(self, name=None):\n",
    "        super(ThreeLayerMLP, self).__init__(name=name)\n",
    "        self.dense_1 = layers.Dense(64, activation='relu', name='dense_1')\n",
    "        self.dense_2 = layers.Dense(64, activation='relu', name='dense_2')\n",
    "        self.pred_layer = layers.Dense(10, name='predictions')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.dense_2(x)\n",
    "        return self.pred_layer(x)\n",
    "    \n",
    "def get_model():\n",
    "    return ThreeLayerMLP(name='3_layer_mlp')\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要记住一点：没有被用过的 subclassed model 无法被保存，这是因为 subclassed model 需要在一些数据上调用来创建权重。直到被调用，模型才会知道输入数据的 shape 和 dtype。而在 Functional 模型中，输入的 shape 和 dtype 是提前指定的（通过 keras.Input(...)），所以 Functional 模型被初始化后就可以被保存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.3026\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer=keras.optimizers.RMSprop())\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=1)\n",
    "# Reset metrics before saving so that loaded model has same state,\n",
    "# since metric states are not preserved by Model.save_weights\n",
    "model.reset_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有三种方法可以保存、恢复 subclassed model：\n",
    "\n",
    "**Approach 1:**\n",
    "\n",
    "保存 subclassed model 的推荐方式是使用 save_weights 来创建 TensorFlow SavedModel checkpoint，会包含模型所有变量的值：\n",
    "* The layers' weights\n",
    "* The optimizer's state\n",
    "* Any variables associated with stateful model metrics (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('path_to_my_weights', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions for future checks\n",
    "predictions = model.predict(x_test)\n",
    "# Also save the loss on the first batch\n",
    "# to later assert that the optimizer state was preserved\n",
    "first_batch_loss = model.train_on_batch(x_train[:64], y_train[:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了恢复模型，需要访问创建模型的代码，为了恢复 optimizer 状态和 the state of any stateful metric，需要在调用 load_weights 之前编译模型（配置必须一致），并用一些数据来调用它（如下面的 train_on_batch）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model\n",
    "new_model = get_model()\n",
    "new_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  optimizer=keras.optimizers.RMSprop())\n",
    "\n",
    "# This initializes the variables used by the optimizers,\n",
    "# as well as any stateful metric variables\n",
    "new_model.train_on_batch(x_train[:1], y_train[:1])\n",
    "\n",
    "# Load the state of the old model\n",
    "new_model.load_weights('path_to_my_weights')\n",
    "\n",
    "# Check that the model state has been preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# The optimizer state is preserved as well,\n",
    "# so you can resume training where you left off\n",
    "new_first_batch_loss=new_model.train_on_batch(x_train[:64], y_train[:64])\n",
    "assert first_batch_loss == new_first_batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 2:**\n",
    "\n",
    "第二种方法是使用 model.save 保存整个模型，然后使用 load_model 来恢复模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: path_to_my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('path_to_my_model', save_format='tf')\n",
    "\n",
    "# Recreate the exact same model purely from the file\n",
    "new_model = keras.models.load_model('path_to_my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 3:**\n",
    "\n",
    "第三种方法是使用 tf.saved_model.save，这种方法等价于 model.save 的 tf 格式。然后调用 load_model 来恢复："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "tf.saved_model.save(model, 'my_saved_model')\n",
    "# Restoring the model\n",
    "restored_saved_model = keras.models.load_model('my_saved_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
