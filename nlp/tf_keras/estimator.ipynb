{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimators\n",
    "\n",
    "Estimators 是 Tensorflow 的高级 API，封装了以下功能：\n",
    "* training\n",
    "* evaluation\n",
    "* prediction\n",
    "* export for serving\n",
    "\n",
    "我们可以使用 pre-made Estimators 或者自己定制 Estimators，这两者都基于 tf.estimator.Estimater 类。\n",
    "\n",
    "Estimators 的优势为：\n",
    "* 可以在本地或分布式环境中运行 Estimator-based 的模型，而无需进行改动。此外，还可以跑在CPU、GPU 和 TPU 上。\n",
    "* 提供了安全的分布式 training loop，控制如何及何时\n",
    "  1. load data\n",
    "  2. handle exceptions\n",
    "  3. create checkpoint files and recover from failures\n",
    "  4. save summaries for TensorBoard\n",
    "  \n",
    " 用 Estimators 时，将数据输入模块和模型分隔开。\n",
    " \n",
    " ### Pre-made Estimators\n",
    " \n",
    "使用 Pre-made Estimators 比基础的 TensorFlow API 更概念化，无须担心创建计算图或 sessions。此外，pre-made Estimators 可以仅改动很少代码就可以实现不同的模型结构。比如，tf.estimators.DNNClassifier 是一个 pre-made Estimator，基于 dense, feed-forward 网络训练分类模型。\n",
    "\n",
    "#### Stucture of a pre-made Estimators\n",
    "\n",
    "设计基于 pre-made Estimator 的模型通常需要四步：\n",
    "1. 一个或多个数据导入模块\n",
    "\n",
    "比如，可能创建一个导入训练集的 function，和一个导入测试集的 function，每个数据导入功能必须返回两个对象：\n",
    "* 一个 dictionary，key 为 feature name，value 为 Tensors（或 SparseTensors），包含对应的 feature data.\n",
    "* Tensor，包含一个或多个标签\n",
    "\n",
    "比如，下面的代码是 input function 的基本框架："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(dataset):\n",
    "    ...  # manipulate dataset, extracting the feature dict and the label\n",
    "    return feature_dict, lebel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 定义 feature columns\n",
    "\n",
    "每个 tf.feature_column 指定 feature name，type, input pre-processing，下面的例子创建了三个 feature columns，前两个 feature columns 指定了 feature's name, type，第三个 feature column 还定义了 lambda 表示式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define three numeric feature columns.\n",
    "population = tf.feature_column.numeric_column('population')\n",
    "crime_rate = tf.feature_column.numeric_column('crime_rate')\n",
    "median_education = tf.feature_column.numeric_column(\n",
    "    'median_education',\n",
    "    normalizer_fn=lambda x: x - global_education_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 实例化相关的 pre-made Estimator\n",
    "\n",
    "例子为名为 LinearClassifier 的 pre-made Estimator 的实例化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an estimator, passing the feature columns.\n",
    "estimator = tf.estimator.LinearClassifier(\n",
    "    feature_columns=[population, crime_rate, median_education])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 调用 training, evaluation, inference 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'input_fn' is the function created in Step 1\n",
    "estimator.train(input_fn=my_training_set, steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果不使用 pre-made Estimators，就必须自己实现 preceding features.\n",
    "\n",
    "### Custom Estimators\n",
    "\n",
    "Estimator 的核心是 model function，model function 是创建图来进行训练、评估、预测等的方法。当使用 pre-made Estimator 时，model function 是已经实现好的了，当使用定制 Estimator 时，需要自己实现 Estimator。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用 tf.keras.estimator.model_to_estimator 将 Keras 模型转为 Estimator，这么做的好处是可以进行分布式训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
      "9412608/9406464 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "keras_mobilenet_v2 = tf.keras.applications.MobileNetV2(input_shape=(160, 160, 3), include_top=False)\n",
    "keras_mobilenet_v2.trainalbe = False\n",
    "\n",
    "estimator_model = tf.keras.Sequential([\n",
    "    keras_mobilenet_v2,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "estimator_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\kazh\\AppData\\Local\\Temp\\tmpdvlkif6b\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:From C:\\Users\\kazh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\kazh\\\\AppData\\\\Local\\\\Temp\\\\tmpdvlkif6b', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001FF5DD88D30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "est_mobilenet_v2 = tf.keras.estimator.model_to_estimator(keras_model=estimator_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 160  # All images will be resized to 160*160\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/127.5) - 1\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(batch_size):\n",
    "    data = tfds.load('cats_vs_dogs', as_supervised=True)\n",
    "    train_data = data['train']\n",
    "    train_data = train_data.map(preprocess).shuffle(500).batch(batch_size)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用 Estimator 的训练方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kazh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "\u001b[1mDownloading and preparing dataset cats_vs_dogs (786.68 MiB) to C:\\Users\\kazh\\tensorflow_datasets\\cats_vs_dogs\\2.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kazh\\AppData\\Roaming\\Python\\Python37\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "WARNING:absl:1738 images were corrupted and were skipped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kazh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kazh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_datasets\\core\\file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset cats_vs_dogs downloaded and prepared to C:\\Users\\kazh\\tensorflow_datasets\\cats_vs_dogs\\2.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='C:\\\\Users\\\\kazh\\\\AppData\\\\Local\\\\Temp\\\\tmpdvlkif6b\\\\keras\\\\keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='C:\\\\Users\\\\kazh\\\\AppData\\\\Local\\\\Temp\\\\tmpdvlkif6b\\\\keras\\\\keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting from: C:\\Users\\kazh\\AppData\\Local\\Temp\\tmpdvlkif6b\\keras\\keras_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting from: C:\\Users\\kazh\\AppData\\Local\\Temp\\tmpdvlkif6b\\keras\\keras_model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-started 158 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-started 158 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\kazh\\AppData\\Local\\Temp\\tmpdvlkif6b\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\kazh\\AppData\\Local\\Temp\\tmpdvlkif6b\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.68413043, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.68413043, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.359472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.359472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.23285642, step = 100 (278.190 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.23285642, step = 100 (278.190 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.364304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.364304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.092917904, step = 200 (274.505 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.092917904, step = 200 (274.505 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 217 into C:\\Users\\kazh\\AppData\\Local\\Temp\\tmpdvlkif6b\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 217 into C:\\Users\\kazh\\AppData\\Local\\Temp\\tmpdvlkif6b\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.348542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.348542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.11653484, step = 300 (286.903 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.11653484, step = 300 (286.903 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.359595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.359595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.069667876, step = 400 (278.098 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.069667876, step = 400 (278.098 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 430 into C:\\Users\\kazh\\AppData\\Local\\Temp\\tmpdvlkif6b\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 430 into C:\\Users\\kazh\\AppData\\Local\\Temp\\tmpdvlkif6b\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 500 into C:\\Users\\kazh\\AppData\\Local\\Temp\\tmpdvlkif6b\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 500 into C:\\Users\\kazh\\AppData\\Local\\Temp\\tmpdvlkif6b\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.13700406.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.13700406.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x1ff6105deb8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_mobilenet_v2.train(input_fn=lambda: train_input_fn(32), steps=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样，调用 evaluate 方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-04-23T14:38:52Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-04-23T14:38:52Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\kazh\\AppData\\Local\\Temp\\tmpdvlkif6b\\model.ckpt-500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\kazh\\AppData\\Local\\Temp\\tmpdvlkif6b\\model.ckpt-500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [4/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [4/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [5/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [5/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [6/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [6/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [7/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [7/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [8/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [8/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [9/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-04-23-14:38:58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-04-23-14:38:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 500: accuracy = 0.54375, global_step = 500, loss = 0.7890236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 500: accuracy = 0.54375, global_step = 500, loss = 0.7890236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: C:\\Users\\kazh\\AppData\\Local\\Temp\\tmpdvlkif6b\\model.ckpt-500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: C:\\Users\\kazh\\AppData\\Local\\Temp\\tmpdvlkif6b\\model.ckpt-500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.54375, 'loss': 0.7890236, 'global_step': 500}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_mobilenet_v2.evaluate(input_fn=lambda: train_input_fn(32), steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 再看两个例子：\n",
    "1. Build a linear model with Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1  female  38.0                   1      0  71.2833  First        C   \n",
       "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3  female  35.0                   1      0  53.1000  First        C   \n",
       "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset.\n",
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')\n",
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(627, 264)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.shape[0], dfeval.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ff00da3c50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dftrain.age.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ff015531d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dftrain.sex.value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '% survive')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat([dftrain, y_train], axis=1).groupby('sex').survived.mean().plot(kind='barh').set_xlabel('% survive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
    "                       'embark_town', 'alone']\n",
    "NUMERIC_COLUMNS = ['age', 'fare']\n",
    "feature_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = dftrain[feature_name].unique()\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_function 指明了数据是怎样转为 tf.data.Dataset 的，tf.data.Dataset 接收多种源，例如 dataframe, csv-formatted file 等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
    "    def input_function():\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000)\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "        return ds\n",
    "    return input_function\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, y_train)\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some feature keys: ['sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n",
      "A batch of class: [b'Third' b'First' b'Third' b'Third' b'Third' b'Third' b'First' b'Third'\n",
      " b'Third' b'Third']\n",
      "A batch of Labels: [1 1 0 0 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "ds = make_input_fn(dftrain, y_train, batch_size=10)()\n",
    "for feature_batch, label_batch in ds.take(1):\n",
    "    print('Some feature keys:', list(feature_batch.keys()))\n",
    "    print('A batch of class:', feature_batch['class'].numpy())\n",
    "    print('A batch of Labels:', label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入所有 base features 后，就可以训练模型了，直接调用 tf.estimator API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.77272725, 'accuracy_baseline': 0.625, 'auc': 0.8317417, 'auc_precision_recall': 0.7875298, 'average_loss': 0.4910239, 'label/mean': 0.375, 'loss': 0.4813112, 'precision': 0.7294118, 'prediction/mean': 0.322374, 'recall': 0.6262626, 'global_step': 200}\n"
     ]
    }
   ],
   "source": [
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "linear_est.train(train_input_fn)\n",
    "result = linear_est.evaluate(eval_input_fn)\n",
    "\n",
    "clear_output()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\kazh\\AppData\\Local\\Temp\\tmplxkjccxh\\model.ckpt-200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\kazh\\AppData\\Local\\Temp\\tmplxkjccxh\\model.ckpt-200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ff61e80be0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_dicts = list(linear_est.predict(eval_input_fn))\n",
    "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n",
    "\n",
    "probs.plot(kind='hist', bins=20, title='predicted probabilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1.05)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_eval, probs)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlim(0,)\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create an Estimator from a Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(3)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an input function**\n",
    "\n",
    "Estimator 需要控制 input pipeline 合适及怎样被创建，这就需要实现 input_fn。Estimator 通过无参方式调用这个函数，input_fn 必须返回 tf.data.Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn():\n",
    "    split = tfds.Split.TRAIN\n",
    "    ds = tfds.load('iris', split=split, as_supervised=True)\n",
    "    ds = ds.map(lambda features, labels: ({'dense_1_input': features}, labels))\n",
    "    ds = ds.batch(32).repeat()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dense1_input': <tf.Tensor: id=44836, shape=(32, 4), dtype=float32, numpy=\n",
      "array([[6.1, 2.8, 4.7, 1.2],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [5.7, 4.4, 1.5, 0.4]], dtype=float32)>}\n",
      "tf.Tensor([1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for features_batch, labels_batch in input_fn().take(1):\n",
    "    print(features_batch)\n",
    "    print(labels_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.Model 可以使用 tf.estimator API 训练，方法是通过 tf.keras.estimator.model_to_estimator 将 tf.keras.Model 转为 tf.estimator.Estimator 对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\kazh\\\\AppData\\\\Local\\\\Temp\\\\tmp7hmmgdf7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001FF01F06B38>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\kazh\\\\AppData\\\\Local\\\\Temp\\\\tmp7hmmgdf7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001FF01F06B38>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "model_dir = tempfile.mkdtemp()\n",
    "keras_estimator = tf.keras.estimator.model_to_estimator(\n",
    "    keras_model=model, model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='C:\\\\Users\\\\kazh\\\\AppData\\\\Local\\\\Temp\\\\tmp7hmmgdf7\\\\keras\\\\keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='C:\\\\Users\\\\kazh\\\\AppData\\\\Local\\\\Temp\\\\tmp7hmmgdf7\\\\keras\\\\keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting from: C:\\Users\\kazh\\AppData\\Local\\Temp\\tmp7hmmgdf7\\keras\\keras_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting from: C:\\Users\\kazh\\AppData\\Local\\Temp\\tmp7hmmgdf7\\keras\\keras_model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-started 4 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-started 4 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\kazh\\AppData\\Local\\Temp\\tmp7hmmgdf7\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\kazh\\AppData\\Local\\Temp\\tmp7hmmgdf7\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.0850353, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.0850353, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 164.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 164.474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.3704013, step = 100 (0.611 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.3704013, step = 100 (0.611 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 174.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 174.825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8164963, step = 200 (0.571 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8164963, step = 200 (0.571 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 175.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 175.438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.56801164, step = 300 (0.570 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.56801164, step = 300 (0.570 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 176.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 176.367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.57276267, step = 400 (0.567 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.57276267, step = 400 (0.567 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 500 into C:\\Users\\kazh\\AppData\\Local\\Temp\\tmp7hmmgdf7\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 500 into C:\\Users\\kazh\\AppData\\Local\\Temp\\tmp7hmmgdf7\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.512438.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.512438.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-04-23T16:08:23Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-04-23T16:08:23Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\kazh\\AppData\\Local\\Temp\\tmp7hmmgdf7\\model.ckpt-500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\kazh\\AppData\\Local\\Temp\\tmp7hmmgdf7\\model.ckpt-500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [2/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [4/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [4/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [5/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [5/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [6/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [6/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [7/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [7/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [8/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [8/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [9/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [9/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [10/10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-04-23-16:08:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-04-23-16:08:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 500: global_step = 500, loss = 0.47769132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 500: global_step = 500, loss = 0.47769132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: C:\\Users\\kazh\\AppData\\Local\\Temp\\tmp7hmmgdf7\\model.ckpt-500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: C:\\Users\\kazh\\AppData\\Local\\Temp\\tmp7hmmgdf7\\model.ckpt-500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval result: {'loss': 0.47769132, 'global_step': 500}\n"
     ]
    }
   ],
   "source": [
    "keras_estimator.train(input_fn=input_fn, steps=500)\n",
    "eval_result = keras_estimator.evaluate(input_fn=input_fn, steps=10)\n",
    "print('Eval result: {}'.format(eval_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
